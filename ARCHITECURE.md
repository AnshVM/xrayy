### Data Model

#### pipelines
  - id (provided by user, apart from the one auto generated by mongodb)
  - label (Common accross the same pipeline)

  - startedAt, finishedAt, duration

  - error 
    - message
    - code

  - status (success or failure)
  

#### stages
  - pipelineId
  - type (fixed options to choose from)
    - 'retrieval' | 'scoring' | 'filtering' | 'generation' | 'ranking' | 'raw'
    - 'raw' allows any input and output but does provide any addition benefits over just storing data.
    - All other stages come with some **restrictions on the input and output**.

  - input
    - any (for storing raw inputs)
    - candidates (For storing lists, used in particular types of stages)

  - output
    - any (for storing raw inputs)
    - candidates (For storing lists, used in particular types of stages)
      - id
      - candidate (basically any json data)
    - filteredCandidates (Stores output for filtering stage)
      - passed 
      - reasonLabel
      - reasonText
  
    - scoredCandidates (For scoring stage)
      - score
      - candidate

    - generatedCandidates (For generation stage)
      - candidate
      - reason

  - metadata (Stores computed metadata unique to different types of stages)


#### Why not put them in a single collection?
-  That would mean storing stages as arrays in Pipeline documents
-  It adds the overhead of joining these two tables after querying, but querying / filtering over embedded arrays won't work well, plus the documents would get bloated.

#### Stage types
- Without these it would just be a logging system.
- Allows us to pre compute common metrics (metadata) for debugging.

#### Special input and output types for different Stage types
- Allows us to structure data for easy indexing and querying
- Eg: storing 'score' or 'reason_label' as special fields 
- While also storing rest of the raw data.


### Queryability

**A user wants to ask: "Show me all runs where the filtering step eliminated more than 90% of candidates" ?**

```typescript
{
  stage: {
    type: 'filtering'
    $failRatio: {$gt: 0.9}
  }
}
```

**For a specific pipeline**
```typescript 
{
  pipeline: {
    label: 'competitor_discovery'
  }
  stage: {
    type: 'filtering'
    $failRatio: {$gt: 0.9}
  }
}
```

This assumes the developer has done the following:
- Used a class annotated with the decorator ```@Pipeline()```
- Used a method annotated with the decorator ```@FilteringStage()```
- Anottated the input array to the method with ```@Candidates()```

The backend pre computes the `failRatio` metric along with others, in case of a Filter stage.

**Can this be used for a million use cases**
It can cover many use cases, but not every. For some it would not be more that a logging system.
But the data model is very extendible.
One nice approach to scale this would be to
**allow developers to write their own plugins**

### Scalability
**Consider a step that takes 5,000 candidates as input and filters down to 30**
One thing is for sure, I would never suggest anything that the developer has not 
explicily opted into.
Sampling - One thing we could is randomly remove some of the candidates that were filtered out.
The whole point of the system is to help you find issues in your Pipelines.
If the number is large enough, the rest of the data should still be enough to pinpoint issues.
Furthermore even after summarising reasons, you still have to store deterministic data, can't summarise that.
Also summarising reasons might make it more difficult to debug an LLMs decision making.

We could summarise, but it does not fit in well with xray. We could set a hard limit on the reason length
and truncate reasons, and warn the users about it.

Another approach, which is possible in only some cases tho, is to use reason labels along with reason text. 
For eg: Store simple labels like 'price_too_high'. Let the developer predefine these labels for a stage.
That we even if we have to delete the 'reason' documents, we can store for a stage label
{failed: {price_too_high: 400}}
Means, for this stage, 400 candidates were removed because their price was too high. 
That way we still preserve some information. 

### Developer Experience

The most basic thing you could do is use `@RawStage`, at which point you're just using it as a logging system.

```typescript

@Pipeline('AgenticPipeline', {id: 'id'})
class AgenticPipeline {
  private id: string;

  constructor(id: string) {
    this.id = id;
  }

  @Entrypoint()
  async function findMatch(product: Product, candidates: Product[]) {
    const filters = this.generateFilters(product);

    const filtered = this.filter(products);

    const ranked = this.rank(products);

    return ranked[0];
  }

  // this would capture the filter-generation step as a raw stage
  // Would capture the product input as inputProduct and also captures
  // the output
  @RawStage('filter-generation')
  generateFilters(@RawInput('inputProduct') product: Product) {
    return filters;
  } 
}
```

```typescript
  @FilteringStage('filtering-stage', {id: 'id', passed: 'passed'})
  filter(@Candidates('products') products: Product[]) {
    return products.map((product) => {
      if(passFilter(product)) {
        return {...product, passed: true};
      }
      return {...product, passed: false};
    })
  }
```

This would capture the stage as a 'filtering' stage, capture the input and outputs.
And compute metrics which might be useful when querying.

Extending this example:
Some stages allow for tracking special fields.
In the filtering stage, we can track the reasonText and reasonLabel field.
The rest of the output will also be saved, the tracked ones can be indexed and 
queried on.

```typescript
  @FilteringStage('filtering-stage', {id: 'id', passed: 'passed', reasonLabel: 'reason'})
  filter(@Candidates('products') products: Product[]) {
    return products.map((product) => {
      if(passFilter(product)) {
        return {...product, passed: true, reason: 'price_too_high' };
      }
      return {...product, passed: false, reason: 'passed_filters'};
    })
  }
```

**What happens to the pipeline if the X-Ray backend is unavailable?**
The sdk logs it to the console and moves on.
We can have a fallback to store the logs redis or somewhere
but I am not sure if that overhead is worth it.

### Real world use case where I would have used xray.
A lot of my work in the past 2 years has involved working with a 
fashion search engine.
Can't get into too much detail but here's an high level idea.

- Search term parsing, generates key terms
  - Generation Stage.
- Search term, filters generation
  - Again, Generation Stage
- Querying the database
  - Retrieval stage
- There are multiple scoring stages involved
  - Scoring stage 
- Final reranking
  - Ranking stage

The metrics computed by xray for the scoring and ranking stage would have been particulary helpful.


### Improving for production
There's so much that has come to my mind, and I've probably forgotten some.

**1. Developer Experience**
While the integration is neat, but enforces that the methods written have certain inputs 
and outputs, which is fine, but the problem is that none of these are validated at 
compile time. The sdk just hopes the developer is well versed with the documentation
and validates inputs and outputs and runtime.
This is one of the core things I would want to improve.

2. Creating a plugin system / allowing custom indexes
While the model covers many use cases, it can never cover all.
We can allow users to create their own plugins
We can also allow users to mark certain fields as special,
so that they can use it for easier querying.

3. Better error handling / warnings
I should have put this on number 1 actually.

4. A lot more that have crossed my mind, lost, waiting to be recalled.







